# -*- coding: utf-8 -*-
"""M22AIE212DLOPS Assignment 1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cfmao7ISC0pJye7mhuGa9VfR0TDvJQ0P
"""

import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.optim as optim
from sklearn.metrics import accuracy_score
from torch.utils.data import Dataset, DataLoader, Subset
from sklearn.model_selection import KFold
from sklearn.preprocessing import LabelEncoder
from sklearn.datasets import load_iris

from google.colab import drive
drive.mount('/content/drive')

"""## Custom Dataset for the Iris Dataset"""

data = load_iris()
columns = ['sepal_length','sepal_width', 'petal_length','petal_width']
df_iris = pd.DataFrame(data["data"],columns = columns)
df_iris["class"] = data["target"]
classes = ['Setosa','Versicolour','Virginica']

print(load_iris()['DESCR'])

df_iris.isnull().sum()

"""
### 1. Dataset Initialization

 Load the entire dataset into memory when we initialize it (**init** method). We’ll also pass in arguments to enable K-Fold cross validation.

### 2. Data Loading and Preprocessing

The **preprocess_data** method loads the IRIS dataset. It handles missing values, label encodes categorical variables, and converts the label to an integer.

### 3. Data Retrieval

The **getitem** method retrieves individual data samples, where features and labels are prepared and returned on demand.

### 4. K-Fold Cross Validation Support

The **get_splits** method handles dataset splitting for cross-validation. It’s used along with the _get_subset method.

### 5. Implementing __len__() for Dataset Length
The **len** method returns the total number of samples in the dataset."""

class IRISData(Dataset):
    """
    Custom dataset class for handling the IRIS dataset.
    """

    def __init__(self,current_fold, num_fold=10):
        """
        Load the IRIS dataset and perform preprocessing.

        Args:
            df_path (str): Path to the Titanic dataset CSV file.
            current_fold (int): The current fold of the dataset.
            num_fold (int): The total number of folds to split the dataset into.
        """
        super().__init__()

        self.df = self.load_data()
        self.num_fold = num_fold
        self.current_fold = current_fold

        # Use KFold to split the dataset into 'num_fold' folds
        self.kf = KFold(n_splits=num_fold, shuffle=True, random_state=42)

    def load_data(self):
        """
        Reads the Iris dataset

        Returns:
            DataFrame: A Pandas DataFrame
        """
        data = load_iris()
        columns = ['sepal_length','sepal_width', 'petal_length','petal_width']
        df_iris = pd.DataFrame(data["data"],columns = columns)
        df_iris["target"] = data["target"]
        return df_iris

    def __len__(self):
        """
        Returns the length of the dataset.
        """
        return len(self.df)

    def __getitem__(self, idx):
        """
        Retrieves the features and label at the given index.

        Args:
            idx (int): The index of the dataset element to retrieve.

        Returns:
            dict: A dictionary containing the features and label of the dataset at the given index.
        """

        # Extract passenger data
        row = self.df.iloc[idx]
        sepal_length = row['sepal_length']
        sepal_width = row['sepal_width']
        petal_length = row['petal_length']
        petal_width = row['petal_width']
        target = row['target']

        # Create feature tensor
        features = torch.tensor([sepal_length, sepal_width, petal_length, petal_width], dtype=torch.float)

        # Create label tensor
        label = torch.tensor(target, dtype=torch.long)

        return {
            'features': features,
            'label': label,
        }

    def get_splits(self):
        """
        Splits the dataset into training and validation subsets.

        Returns:
            tuple: A tuple containing the training and validation subsets.
        """

        fold_data = list(self.kf.split(self.df))
        train_indices, val_indices = fold_data[self.current_fold]

        train_data = self._get_subset(train_indices)
        val_data = self._get_subset(val_indices)

        return train_data, val_data

    def _get_subset(self, indices):
        """
        Returns a Subset of the dataset at the given indices.

        Args:
            indices (list): A list of indices specifying the subset of the dataset to return.

        Returns:
            Subset: A Subset of the dataset at the given indices.
        """
        return Subset(self, indices)

"""### 6. Using the Dataset Class in our Training Loop

Now that we have our dataset class, let’s use it to train a machine learning model.

First, define the model architecture and hyperparameter configuration.
"""

import torch.nn.functional as F

class SimpleFeedForwardNN(nn.Module):
    def __init__(self, input_size, hidden_layer_1_size,hidden_layer_2_size, output_size):
        super(SimpleFeedForwardNN, self).__init__()
        self.fc1 = nn.Linear(input_size, hidden_layer_1_size)
        self.relu1 = nn.ReLU()
        self.fc2 = nn.Linear(hidden_layer_1_size, hidden_layer_2_size)
        self.relu2 = nn.ReLU()
        self.fc3 = nn.Linear(hidden_layer_2_size, output_size)
        self.softmax = nn.Softmax(dim = 1)

    def forward(self, x):
        x = self.fc1(x)
        x = self.relu1(x)
        x = self.fc2(x)
        x = self.relu2(x)
        x = self.fc3(x)
        x = self.softmax(x)
        return x

class Config:
    input_size = 4  # Number of input features
    hidden_layer_1_size = 5  # Size of the hidden layer
    hidden_layer_2_size = 7  # Size of the hidden layer
    output_size = 3
    learning_rate = 0.003
    num_epochs = 256
    batch_size = 64
    num_fold = 10

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
criterion = nn.CrossEntropyLoss()

"""In each fold, create an instance of the TitanicData class, specifying which fold you’re on. Split the data into training and validation sets. with **.get_splits()**. Then use PyTorch’s DataLoader class, which allows us to easily retrieve minibatches of data. Inside each epoch, we iterate through the DataLoaders to train the model and evaluate performance on the validation set.

## Setting Up Tensorboard
"""

from torch.utils.tensorboard import SummaryWriter

# default `log_dir` is "runs" - we'll be more specific here
writer = SummaryWriter('/content/drive/MyDrive/Assignments/DLOPS/Assignment1/runs/iris_experiment')

"""## Visualising model architecture and tracking training :"""

fold_results = []  # Store validation results for each fold
fold_models = [] # Store model trained on each fold

best_overall_loss = 10000000  # Initialize the best overall loss tracker
best_overall_model = None  # Initialize the best overall model tracker

for fold in range(Config.num_fold):
    # Create data handler for the current fold
    data_handler = IRISData(current_fold=fold, num_fold=Config.num_fold)

    # Split the dataset into training and validation subsets
    train_data, val_data = data_handler.get_splits()

    # Create data loaders using the batch_size from the Config class
    train_loader = DataLoader(train_data, batch_size=Config.batch_size, shuffle=True)
    val_loader = DataLoader(val_data, batch_size=Config.batch_size)

    # Create a new instance of the model for each fold
    model = SimpleFeedForwardNN(Config.input_size, Config.hidden_layer_1_size,Config.hidden_layer_2_size, Config.output_size)
    model.to(device)

    # Define a new optimizer for each fold to reset the model parameters
    optimizer = optim.Adam(model.parameters(), lr=Config.learning_rate)

    best_val_loss = 10000000  # Initialize the best validation loss for the current fold

    # Training loop for the current fold
    for epoch in range(Config.num_epochs):
        model.train()
        total_loss = 0.0
        for batch in train_loader:

            # Retrieve features and labels from the current batch
            features = batch['features'].to(device)
            labels = batch['label'].to(device)

            # Forward pass
            outputs = model(features)

            # Calculate the loss using BCEWithLogitsLoss
            loss = criterion(outputs,labels)

            # Backpropagation and optimization with gradient clipping
            optimizer.zero_grad()
            loss.backward()

            if torch.isnan(loss):
                print("NaN loss detected. Check your data and training settings.")
                break

            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)  # Add gradient clipping to get rid of from exploding gradient problem
            optimizer.step()

            total_loss += loss.item()

        average_loss = total_loss / len(train_loader)

        # Log training loss to TensorBoard
        writer.add_scalar(f'Training Loss/Fold_{fold + 1}', average_loss, epoch + 1)

        # Validation for the current fold
        model.eval()
        val_total_loss = 0.0
        all_labels = []
        all_predictions = []
        with torch.no_grad():
            for batch in val_loader:
                # Your validation code here
                features = batch['features'].to(device)
                labels = batch['label'].to(device)  # Convert labels to float for BCE loss

                # Forward pass
                outputs = model(features)
                #print(outputs)

                val_loss = criterion(outputs,labels)
                val_total_loss += val_loss.item()

                predictions = outputs.argmax(dim = 1)
                #print(predictions)

                all_labels.extend(labels.tolist())
                all_predictions.extend(predictions.tolist())

        average_val_loss = val_total_loss / len(val_loader)

        # Log Validation loss to TensorBoard
        writer.add_scalar(f'Validation Loss/Fold_{fold + 1}', average_val_loss, epoch + 1)

        # Calculate accuracy for the current fold
        accuracy = accuracy_score(all_labels, all_predictions)
        print(f'Fold [{fold + 1}/{Config.num_fold}] - Epoch [{epoch + 1}/{Config.num_epochs}] - Loss: {average_loss:.4f} - Validation Loss: {average_val_loss:.4f} - Validation Accuracy: {accuracy:.4f}')

        # Log Validation Accuracy to TensorBoard
        writer.add_scalar(f'Validation Accuracy /Fold_{fold + 1}', accuracy, epoch + 1)

        # Check if the current model achieves a better validation loss
        if best_val_loss > average_val_loss:
            best_val_loss = average_val_loss

            # Save the best model for the current fold
            best_model_state_dict = model.state_dict()

    # Store validation results for the current fold
    fold_results.append(accuracy)

    # Save the model for the current fold
    fold_models.append(model)

    # Load the best model state into a new model instance
    best_model = SimpleFeedForwardNN(Config.input_size, Config.hidden_layer_1_size, Config.hidden_layer_2_size, Config.output_size)
    best_model.load_state_dict(best_model_state_dict)
    best_model.to(device)

    # Save the best model for the current fold
    fold_models.append(best_model)

    # Check if the current fold has the best overall accuracy
    if best_overall_loss > best_val_loss :
        best_overall_loss = best_val_loss

        print(f"Update the best model across all folds with validation loss : {best_overall_loss}")
        best_overall_model = best_model

# Calculate and print the average validation accuracy across all folds
average_accuracy = sum(fold_results) / len(fold_results)
print(f'Average Validation Accuracy: {average_accuracy:.4f} across {Config.num_fold} folds')

for batch in train_loader:
  data = batch['features']
  labels = batch['label']

writer.add_graph(model, data)
writer.close()

"""## Add PR curve"""

## Getting the best model
net = best_overall_model

# 1. gets the probability predictions in a test_size x num_classes Tensor
# 2. gets the preds in a test_size Tensor
# takes ~10 seconds to run
class_probs = []
class_label = []
with torch.no_grad():
    for data in val_loader:
        features, labels = data["features"],data["label"]
        output = net(features)
        class_probs_batch = [F.softmax(el, dim=0) for el in output]

        class_probs.append(class_probs_batch)
        class_label.append(labels)

test_probs = torch.cat([torch.stack(batch) for batch in class_probs])
test_label = torch.cat(class_label)

# helper function
def add_pr_curve_tensorboard(class_index, test_probs, test_label, global_step=0):
    '''
    Takes in a "class_index" from 0 to 9 and plots the corresponding
    precision-recall curve
    '''
    tensorboard_truth = test_label == class_index
    tensorboard_probs = test_probs[:, class_index]

    writer.add_pr_curve(classes[class_index],
                        tensorboard_truth,
                        tensorboard_probs,
                        global_step=global_step)
    writer.close()

# plot all the pr curves
for i in range(len(classes)):
    add_pr_curve_tensorboard(i, test_probs, test_label)

"""# Feature Representation Visualization
We can visualize the lower dimensional representation of higher dimensional data via the add_embedding method
"""

# Hook function
def hook_fn(module, input, output):
    global layer_output2
    layer_output2 = output
layer2 = net.fc2

# Register the hook
handle = layer2.register_forward_hook(hook_fn)

_ = net(data_handler[:]['features'].T)

# get the class labels for each image
class_labels = [classes[lab] for lab in data_handler[:]['label']]

# log embeddings
writer.add_embedding(layer_output2,
                    metadata=class_labels, global_step=0)
writer.close()

layer_output2.shape,len(class_labels)

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext tensorboard

!kill 1673

# Commented out IPython magic to ensure Python compatibility.
# %tensorboard --logdir /content/drive/MyDrive/Assignments/DLOPS/Assignment1/runs

